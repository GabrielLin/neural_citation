{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural citation network for local citation recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ncn.evaluation import Evaluator\n",
    "from ncn.data import get_datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_weights = \"/home/timo/Downloads/best_model_bn_TDNN/NCN_7_17_10.pt\"\n",
    "path_to_data = \"/home/timo/DataSets/KD_arxiv_CS/arxiv_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_datasets(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_dict(d):\n",
    "    \"\"\"Display a dict nice and pretty.\"\"\"\n",
    "    for key, value in d.items():\n",
    "        print(f\"Citation rank {key}|\\t {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_attention(candidate, translation, attention):\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
    "    \n",
    "    cax = ax.matshow(attention, cmap='bone')\n",
    "   \n",
    "    ax.tick_params(labelsize=15)\n",
    "    ax.set_xticklabels([''] + ['<sos>'] + [t.lower() for t in tokenize_de(candidate)] + ['<eos>'], \n",
    "                       rotation=45)\n",
    "    ax.set_yticklabels([''] + translation)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: Basic statistics\n",
    "1. Removed 8260 triplets of paper data due to empty/missing files.  \n",
    "2. Removed 1 data sample throwing regex error.  \n",
    "3. Removed 161670 context samples where information was missing/could not be parsed from files.   \n",
    "* This leaves __502353 context - citation pairs__ with full information.\n",
    "* __Context vocabulary__ size after processing: __72046__.  \n",
    "* __Title vocabulary__ size after processing: __43208__.  \n",
    "* Number of __citing authors__: __28200__.  \n",
    "* Number of __cited authors__: __169236__. \n",
    "\n",
    "![Context and title length distributions](assets/title_context_distribution.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing with torchtext Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"Neural networks are really cool, especially if they are convolutional.\"\n",
    "authors = \"Jim Foo, Bruce Lee\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bucketting: What it is and why do we need it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citation rank 0|\t Visualizing and understanding convolutional networks\n",
      "Citation rank 1|\t Imagenet classification with   deep convolutional neural networks\n",
      "Citation rank 2|\t Visualizing and understanding convolutional neural   networks\n",
      "Citation rank 3|\t Group equivariant convolutional networks\n",
      "Citation rank 4|\t Two-stream convolutional networks for action   recognition in videos\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning\n",
    "![Context and title length distributions](assets/lecun.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(path_to_weights, data, evaluate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recomms = evaluator.recommend(context, authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_dict(recomms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "![Context and title length distributions](assets/Documentation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
