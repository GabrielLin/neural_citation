{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural citation network for local citation recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ncn.evaluation import Evaluator\n",
    "from ncn.data import get_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: Basic statistics\n",
    "1. Removed 8260 triplets of paper data due to empty/missing files.  \n",
    "2. Removed 1 data sample throwing regex error.  \n",
    "3. Removed 161670 context samples where information was missing/could not be parsed from files.   \n",
    "* This leaves __502353 context - citation pairs__ with full information.\n",
    "* __Context vocabulary__ size after processing: __72046__.  \n",
    "* __Title vocabulary__ size after processing: __43208__.  \n",
    "* Number of __citing authors__: __28200__.  \n",
    "* Number of __cited authors__: __169236__. \n",
    "\n",
    "![Context and title length distributions](assets/title_context_distribution.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_weights = \"/home/timo/Downloads/best_model_bn_TDNN/NCN_7_17_10.pt\"\n",
    "path_to_data = \"/home/timo/DataSets/KD_arxiv_CS/arxiv_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neural_citation.data:Getting fields...\n",
      "INFO:neural_citation.data:Loading dataset...\n",
      "INFO:neural_citation.data:Building vocab...\n"
     ]
    }
   ],
   "source": [
    "data = get_datasets(path_to_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing with torchtext Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bucketting: What it is and why do we need it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neural_citation.evaluation:INITIALIZING NEURAL CITATION NETWORK WITH AUTHORS = True\n",
      "Running on: cpu\n",
      "Number of model parameters: 23,533,236\n",
      "Encoders: # Filters = 128, Context filter length = [4, 4, 5],  Context filter length = [1, 2]\n",
      "Embeddings: Dimension = 128, Pad index = 1, Context vocab = 30002, Author vocab = 30002, Title vocab = 30004\n",
      "Decoder: # GRU cells = 2, Hidden size = 128\n",
      "Parameters: Dropout = 0.2\n",
      "-------------------------------------------------\n",
      "INFO:neural_citation.evaluation:Creating corpus in eval=False mode.\n",
      "INFO:neural_citation.evaluation:Number of samples in BM25 corpus: 1054941\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(path_to_weights, data, eval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"Neural networks are really cool, especially if they are convolutional and on graphs.\"\n",
    "authors = \"Jim Foo, Bruce Lee\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Evaluator' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0e50e6cdefc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dropbox/Documents/KIT/4SEM/1Seminar_KD/neural_citation/ncn/evaluation.py\u001b[0m in \u001b[0;36mrecommend\u001b[0;34m(self, query, citing, top_x)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m# should have option to return attentions somehow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mStringlike\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mciting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mStringlike\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_x\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Performing inference only on the test set.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Evaluator' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "evaluator.recommend(context, authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning\n",
    "![Context and title length distributions](assets/lecun.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "![Context and title length distributions](assets/Documentation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
